\section{A Family of Anisotropic Diffusion Maps}

In this section we investigate the probability space $(\Omega, \mathcal{A}, \mu)$ and therefore assume an infinite number of data points whose distribution is determined by the probability measure $\mu(x)=e^{-U(x)}$. $U$ may be interpreted as a potential function. A motivation for the choice of $\mu$ will be given with \eqref{eq:decompositionProbDistributionfFPO}.

\subsection{Construction of the Family of Diffusions}
Start with a Gaussian kernel $k_\eps(x,y)=e^{-\frac{||x-y||^2}{\eps}}$ and let $\alpha > 0$ being a parameter indexing this family of diffusions.

We can estimate the local density $q_\eps$ by 

\begin{definition}
$$q_\eps(x)=\int_\Omega k_\eps(x,y)d\mu(y)$$
\end{definition}

Now consider the family of (generally) anisotropic kernels

\begin{definition}
$$k_\eps^{(\alpha)}(x,y)=\frac{k_\eps(x,y)}{q_\eps^\alpha(x)q_\eps^\alpha(y)} $$
\end{definition}

We compute the normalization factor\footnote{Note that this factor is the continuous analogue to definition \ref{def:normFunc}.} $d_\eps^{(\alpha)}$

$$d_\eps^{(\alpha)}(x) = \int_\Omega k_\eps^{(\alpha)}(x,y)d\mu(y)$$

and define the forward and symmetric ($p^{(\alpha)}$ and $a^{(\alpha)}$ respectively) transition probability kernels:

\begin{definition}\begin{equation*}\begin{aligned}
&p_\eps^{(\alpha)}(x|y) = \frac{k_\eps^{(\alpha)}(x,y)}{d_\eps^{(\alpha)}(y)} = \text{Pr}\big(x(t+\eps)=x \, |\, x(t)=y\big)\\
&a_\eps^{(\alpha)}(x|y) = \frac{k_\eps^{(\alpha)}(x,y)}{\sqrt{d_\eps^{(\alpha)}(x)d_\eps^{(\alpha)}(y)}}
\end{aligned}\end{equation*}\end{definition}

Now we define the  forward, backward and symmetric Chapman-Kolmogorov operators on functions defined on this probability space, as follows:

\begin{definition}\begin{equation*}\begin{aligned}
T_{f,\eps}^{(\alpha)}[\phi](x) &= \int_\Omega p_\eps^{(\alpha)}(x|y)\phi(y)d\mu(y)\\
T_{b,\eps}^{(\alpha)}[\phi](x) &= \int_\Omega p_\eps^{(\alpha)}(y|x)\phi(y)d\mu(y)\\
T_{s,\eps}^{(\alpha)}[\phi](x) &= \int_\Omega a_\eps^{(\alpha)}(x,y)\phi(y)d\mu(y)
\end{aligned}\end{equation*}\end{definition}

If $\phi(x)$ is the probability of finding the system at location $x$ at time $t = 0$, then $T_{f,\eps}^{(\alpha)}[\phi]$ is the evolution of this probability to time $t = \eps$. Similarly, if $\psi(z)$ is some function on the space, then $T_{b,\eps}^{(\alpha)}[\psi](x)$ is the mean value of that function at time $\eps$ for a random walk that started at $x$, and so $\left(T_{b,\eps}^{(\alpha)}\right)^m[\psi](x)$ is the average value of the function at time $t = m\eps$.

By definition, the operators $T_{f,\eps}^{(\alpha)}$ and $T_{b,\eps}^{(\alpha)}$ are adjoint under the inner product with weight $\mu$, while the operator $T_{s,\eps}^{(\alpha)}$ is self adjoint under this inner product.

Moreover, just like in the discrete case, since $T_{s,\eps}^{(\alpha)}$ is obtained via conjugation of the kernel $p^{(\alpha)}$ all three operators share the same eigenvalues. The corresponding eigenfunctions can be found via
conjugation by $\sqrt{d^{(\alpha)}_\eps}$; i.e.:
If $T_{s,\eps}^{(\alpha)}\phi_s = \lambda\phi_s$, then the corresponding eigenfunctions for $T_{f,\eps}^{(\alpha)}$ and $T_{b,\eps}^{(\alpha)}$ are $\phi_f =
\sqrt{q_\eps}\phi_s$ and $\phi_b = \frac{\phi_s}{\sqrt{q_\eps}}$, respectively.\todo{double check that section}

Since $\sqrt{q_\eps}$ is the first eigenfunction with $\lambda_0 = 1$ of $T_s^{(\alpha)}$, the steady state of the forward operator is simply $q_\eps(x)$, while for the backward operator it is the uniform density, $\phi_b \equiv 1$.

Furthermore, note that the eigenvalues and eigenvectors of the discrete Markov chain described in the previous section are discrete approximations to the eigenvalues and eigenfunctions of these continuous operators.

\subsection{Transition to Diffusion Processes}
Interpreting $\eps$ as a timestep\footnote{While in the case of a finite amount of data, $\eps$ must remain finite so as to have enough neighbors in a ball of radius $\mathcal{O}(\eps^\frac{1}{2})$ near each point $x$, as the number of samples goes to infinity, we can take smaller and smaller values of $\eps$.} and recalling the asymptotic expansions derived in the appendix it is instructive to look at the limit $\eps \rightarrow 0$. In this case, the transition probability densities of the Markov chain (that is continuous in space, but discrete in time) converge to those of a diffusion process, whose time evolution is described by a differential equation

\begin{equation*}
\frac{\partial \phi}{\partial t} = \mathcal{H}_f^{(\alpha)}\phi
\end{equation*}

where $\mathcal{H}_f^{(\alpha)}$ is the infinitesimal generator or propagator of the forward operator, defined as

\begin{definition}\label{def:fFP}\begin{equation*}
\mathcal{H}_f^{(\alpha)}=\lim_{\eps\rightarrow 0}\frac{T_{f,\eps}^{(\alpha)}-I}{\eps}
\end{equation*}\end{definition}

Similarly, the inifinitesimal operator of the backward operator is given by

\begin{definition}\label{def:bFP}\begin{equation*}
\mathcal{H}_b^{(\alpha)}=\lim_{\eps\rightarrow 0}\frac{T_{b,\eps}^{(\alpha)}-I}{\eps}
\end{equation*}\end{definition}

and as shown in the appendix (theorem \ref{thm:bFPO})

\begin{equation*}
\mathcal{H}_b^{(\alpha)}\psi = \Delta\psi - 2(1-\alpha)\nabla\psi\cdot\nabla U
\end{equation*}

as well as 

\begin{equation*}
\mathcal{H}_f^{(\alpha)}\psi = \Delta\psi - 2\alpha\nabla\psi\cdot\nabla U + (2\alpha - 1)\psi(\nabla U\cdot\nabla U - \Delta U)
\end{equation*}

Now we consider the following three choices of $\alpha$:

\begin{enumerate}

\item $\alpha = 0$:
$$\mathcal{H}_f^{(0)}\phi = \Delta\phi - (e^U\Delta e^{-U})\phi$$
Chosing $\alpha = 0$, ``ignoring'' the potential term (in the process of the normalization), we get the normalized graph Laplacian we already dealt with in the first chapter.

\item $\alpha = \frac{1}{2}$:
$$\mathcal{H}_f^{(\frac{1}{2})}\phi = \mathcal{H}_b^{(\frac{1}{2})}\phi = \Delta\phi - \nabla\phi\cdot\nabla U$$
First, note that the infinitesimal operator of the forward and backward operators coincide and reduce to the backward Fokker-Planck equation with potential $U$.

\item $\alpha = 1$:
$$\mathcal{H}_b^{(1)}\phi = \Delta\phi$$
The intention of chosing $\alpha = 1$ is to ``normalize the potential away'' which is successful as the resulting infinitesimal generator is the Laplace-Beltrami operator and thus the corresponding diffusion only captures the geometry of the data, totally neglecting the underlying density $e^{-U}$. As such, it is optimal for tasks like manifold reconstruction.

\end{enumerate}

\subsection{Investigation of Stochastic Processes}
First we start with the definition of a stochastic process:

\begin{definition}
Let $T$ be an ordered set. A \textit{stochastic process} is a collection of random variables $X=\{X_t,t\in T\}$ where, for each $t\in T$, $X_t: E\rightarrow \Omega$ is a random variable from a measurable space $(E, \mathcal{F})$ to another one $(\Omega, \mathcal{G})$.
\end{definition}

From now on, let $T=\Real^+$ be the time and $\Omega=\Real^n$ the \textit{state space}.\footnote{It is important that $x\in\Omega$ does \textit{not} represent a particular particle, but a certain state of the entire system.} \\

Now we want to investigate the time evolution of a system that is described by its state $x(t)$ at time $t$, $(x(t)\in\Omega)$ and is governed by the following stochastic differential equation

\begin{equation}\label{eq:langevin}
\dot{x}=-U(x)+\sqrt{2/\beta}\dot{w}
\end{equation}

where $U(x)$ is the potential energy of a state $x$, $\beta$ is some thermal factor which is inversely proportional to a given temperature and $w(t)$ is the Brownian motion in $n$ dimensions.

Integration of the SDE \eqref{eq:langevin} produces random paths whose distribution defines a time dependent probability distributions on $\Omega$. To study the dynamics of the system, it is convenient to consider the time evolution of these probability distributions as it has been shown\todo{find source} that the transition probability density $p(x, t | x_0, 0)$ of finding the system at location $x$ at time $t$, given an initial location $x_0$ at time $t = 0$ satisfies the forward Fokker-Planck equation

\begin{equation}\label{eq:fokkerplanck}
\frac{\partial p}{\partial t} = \frac{1}{\beta}\Delta p + \nabla\cdot(p\nabla U) =: \mathcal{L}p
\end{equation}

defined in $(x,t)\in \Omega\times\Real^+$ with reflecting boundary conditions on $\partial\Omega$, i.e. $\frac{\partial p}{\partial n} = 0$ where $\frac{\partial}{\partial n}$ is the derivative in the outward normal direction. Furthermore the initial condition is given by the Dirac-Delta function, i.e. $\lim_{t\rightarrow 0} p(x, t | x_0, 0) = \delta(x-x_0)$.

\subsubsection{Eigenvalues of the Fokker-Planck Operator}
As seen in the first chapter one can compute the eigenvalues $\lambda_{\eps, i}^{(\alpha)}$ of $T_{b,\eps}^{(\alpha)}$ by computing those of $T_{s,\eps}^{(\alpha)}$. From definition of $\mathcal{H}_f^{(\alpha)}$ and $\mathcal{H}_b^{(\alpha)}$ it follows that they share the eigenvalues $\mu_i^{(\alpha)}$ which can be written as

\begin{equation*}
\mu_i^{(\alpha)} = \lim_{\eps\rightarrow 0}\frac{\lambda_{\eps, i}^{(\alpha)}-1}{\eps} 
\end{equation*}

and are discrete again. Remember that for $\alpha=\frac{1}{2}$, $\mathcal{H}_f^{(\alpha)}$ and $\mathcal{H}_b^{(\alpha)}$ coincide and become the backward Fokker-Planck operator $\mathcal{L}^*$

\begin{definition}\label{def:bFPO}
$\mathcal{L}^*g = \frac{1}{\beta}\Delta g - \nabla g \cdot\nabla U$
\end{definition}

\begin{lemma}\label{thm:fFPadjointTobFP}
$\mathcal{L}$ and $\mathcal{L}^*$ are adjoint under the standard inner product.
\end{lemma}
\begin{proof}
\begin{equation*}\begin{aligned}
\langle \mathcal{L}^*f, g \rangle
&= \langle \frac{1}{\beta}\Delta f - \nabla g \cdot \nabla U, g \rangle\\
&= \langle \frac{1}{\beta}\Delta f, g \rangle + \langle -\nabla f \cdot \nabla U, g \rangle \\
&= \langle f, \frac{1}{\beta}\Delta g \rangle + \langle -\nabla f, g\cdot \nabla U \rangle \\
&= \langle f, \frac{1}{\beta}\Delta g \rangle + \langle f, \text{div}(g\cdot \nabla U) \rangle \\
&= \langle f, \frac{1}{\beta}\Delta g \rangle + \langle f, \nabla\cdot(g\cdot \nabla U) \rangle = \langle f, \mathcal{L}g \rangle
\end{aligned}\end{equation*}
\end{proof}

$\mathcal{L}$ and $\mathcal{L}^*$ being adjoint implies that $\mu_i^{(\frac{1}{2})}$ are not only the eigenvalues of $\mathcal{L}$, but also of $\mathcal{L}^*$.

\subsubsection{Computing the Transition Probability Density}
% sources: http://www.wisdom.weizmann.ac.il/~nadler/Publications/diffusion_map_MMS.pdf, http://en.wikipedia.org/wiki/Sturm%E2%80%93Liouville_theory#Application_to_PDEs, http://howellkb.uah.edu/DEtext/Part7_BVProbs/SL.pdf p32f
For simplicity's sake the calculations will be done in one dimension for the forward Fokker-Planck operator.

First of all, notice that in one dimension \eqref{eq:fokkerplanck} may be written as

\begin{equation}\label{eq:fFP1D}\begin{aligned}
\frac{\partial p}{\partial t} &= \frac{\partial^2 p}{\partial x^2}\frac{1}{\beta} + \frac{\partial}{\partial x}\left(p \frac{\partial U}{\partial x} \right)\\
&=\frac{\partial^2 p}{\partial x^2}\underbrace{\frac{1}{\beta}}_{=:f(x)} + \frac{\partial p}{\partial x}\underbrace{\frac{\partial U}{\partial x}}_{=:g(x)} + p\underbrace{\frac{\partial^2 U}{\partial x^2}}_{=:h(x)}
\end{aligned}\end{equation}

and the reflecting boundary conditions simplify to $p(a,t)=p(b,t)=0$.

Now apply separation of variables $p(x,t)=X(x)T(t)$ and rewrite \eqref{eq:fFP1D} as

\begin{equation}\label{eq:separationOfVariables}
\frac{\mathcal{L}X(x)}{X(x)} = \frac{\frac{d}{dt}T(t)}{T(t)}.
\end{equation}

Since both sides of \eqref{eq:separationOfVariables} only depend on one variable each, they must be equal to a constant, i.e.

\begin{equation}\label{eq:almostSturmLiouville}
\mathcal{L}X(x) = \lambda X(x)
\end{equation}
and
\begin{equation*}
\frac{d}{dt}T(t)=\lambda T(t).
\end{equation*}

\eqref{eq:almostSturmLiouville} is \textit{almost} a regular Sturm-Liouville problem. In order get it into the form

\begin{equation}\label{eq:regularSLproblem}
\frac{d}{dx}\left[\tilde{f}(x)\frac{d\varphi_n}{dx} \right] + \tilde{h}(x)\varphi_n = \tilde{f}(x)\frac{d^2 \varphi_n}{dx^2} + \frac{d \tilde{f}(x)}{dx}\frac{d \varphi_n}{dx}+ \tilde{h}(x)\varphi_n = -\tilde{\lambda}_n w(x)\varphi_n
\end{equation}

we consider the space $L^2([a,b],w)$ with 

\begin{equation}\label{eq:boltzmannEquilibrium}
w = \frac{e^{\int \frac{g}{f}}}{f} = \beta e^{\beta U}
\end{equation}

and 

\begin{equation*}
\langle \phi, \psi \rangle_w = \int_a^b \phi(x)\psi(x)w(x)dx.
\end{equation*}

Note that there is no discrepancy with \eqref{eq:regularSLproblem} when dealing $+\lambda_n$ instead of $-\tilde{\lambda_n}$ as $\tilde{\lambda_n}$ is required to be non-negative and our $\lambda_n$ are non-positive.

\eqref{eq:boltzmannEquilibrium} is not only the eigenfunction to the first eigenvalue $\lambda_0 = 0$ (plug it into \eqref{eq:fFP1D}), but, if normalized to absolute value $1$, is also known as the Boltzmann equilibrium distribution.

We also get $X(a)=X(b)=0$. Let $\varphi_n$ and $\lambda_n$ be the eigenfunctions\footnote{There is no general analytic (exact) solution to Sturm-Liouville problems, but solving a Sturm-Liouville problem is a easier than solving the whole PDE.} and eigenvalues of $\mathcal{L}$ and analogously $\frac{d}{dt}T_n(t)=\lambda_n T(t)$. Note that, as a Sturm-Liouville operator in $L^2([a,b], w(x)dx)$, $\mathcal{L}$ is self-adjoint and its eigenfunctions $\varphi_n$ are orthogonal and maximal.\footnote{See \cite{Teschl2012}.} Without loss of generality assume $\varphi_n$ to be orthonormal.

Now we can write $T_n(t)$ as

\begin{equation}\label{eq:eigenvalOfTn}
T_n(t) = a_n e^{\lambda_n t}
\end{equation}

for some constants $a_n$ that can be written as

\begin{equation*}
a_n = \langle \varphi_n, p(\cdot, 0) \rangle_w
\end{equation*}

Note that $a_n$ is a generalized fourier series of the initial distribution $p(\cdot, 0)$, i.e. $p(\cdot, 0) = \sum_k a_k \varphi_n$ on $[a,b]$ because the set of orthonormal eigenfunctions forms a basis. It is chosen such that \eqref{eq:eigenvalOfTn} holds true for $t=0$. As a result

\begin{equation}\label{eq:decompositionProbDistributionfFPO}
p(x,t) = \sum_{n\geq 0} a_n e^{\lambda_n t} \varphi_n(x)
\end{equation}

From that representation we get that, as $t\rightarrow \infty$, only the first term with $\lambda_0 = 0$ survives, which justifies the naming of \eqref{eq:boltzmannEquilibrium} as Boltzmann \textit{equilibrium} distribution.\footnote{Under the assumption that the system is ergodic, the ergodic theorem tells us that the time average and the space average are the same almost everywhere; as such (and because $\varphi_0$ is continuous), regardless of the initial configuration $x_0\in\Omega$, $\lim_{t\rightarrow\infty} p(x,t | x_0, 0) = \varphi_0(x)$.}

Analogously, for every smooth $f\in L^2(\Omega)$, one can consider $g(x,t) = \mathbb{E}\{f(x(t)) | x(0) ) = x \}$ which satisfies the backward Fokker-Planck equation

\begin{equation*}
\frac{\partial g}{\partial t} = \frac{1}{\beta}\Delta g - \nabla g \cdot\nabla U = \mathcal{L}^*g
\end{equation*}

in the domain $(x,t)\in \Omega\times\Real^+$.

Remember that, as the adjoint\footnote{under the standard inner product} of $\mathcal{L}$, $\mathcal{L}^*$ shares the eigenvalues $\lambda_n$. It is easy to see that
\begin{equation}\label{eq:firstEigenfunctionConstant}
\psi_0(x)=1
\end{equation}
is the eigenfunction corresponding to the eigenvalue $\lambda_0 = 0$.

Analogously to the previous part it can be shown that

\begin{equation*}
g(x,t) = \sum_{n\geq 0} b_n e^{\lambda_n t}\psi_n(x)
\end{equation*}

with 
\todo{check if weight function really is the same - $-\beta$ might be a problem!}
\begin{equation*}
b_n = \langle \psi_n, g(\cdot, 0) \rangle_w.
\end{equation*}

\begin{lemma}
We can normalize $\varphi_n$ and $\psi_n$ to be bi-orthonormal, i.e.
\begin{equation}\label{eq:biorthonormality}
\langle \varphi_i, \psi_j \rangle = \delta_{i,j}.
\end{equation}
\end{lemma}

\begin{proof}
Let $\lambda_i$ be the eigenvalue to the eigenfunction $\varphi_i$ and $\lambda_j$ to $\psi_j$.

\begin{equation*}
\lambda_i \langle \varphi_i, \psi_j \rangle =
\langle \mathcal{L}\varphi_i, \psi_j \rangle =
\langle \varphi_i, \mathcal{L}^*\psi_j \rangle =
\lambda_j \langle \varphi_i, \psi_j \rangle
\end{equation*}
For $\lambda_i \neq \lambda_j$ we get the desired result.
\end{proof}

In the following let $\varphi_i, \psi_j$ be normalized in a way as described above.

Now we get an alternative representation for the coefficients $a_n, b_n$:

\begin{equation}\label{eq:alternativeReprForCoefficients}\begin{aligned}
a_j&= \sum_{i\geq 0} a_i \langle \varphi_i, \psi_j \rangle
    = \langle \sum_{i\geq 0} a_i \varphi_i, \psi_j \rangle
    = \langle f(\cdot, 0), \psi_j \rangle = \psi_j(x_0)\\
b_j&= \sum_{i\geq 0} b_i \langle \varphi_j, \psi_i \rangle
    = \langle \varphi_j, \sum_{i\geq 0} b_i \psi_i \rangle
    = \langle \varphi_j, g(\cdot, 0) \rangle
\end{aligned}\end{equation}

In order to find a connection between the eigenfunctions $\varphi$ and $\psi$ we show
\begin{lemma}
$\mathcal{L}e^{-\beta U}g = e^{-\beta U}\mathcal{L}^*g$
\end{lemma}

\begin{proof}
For simplicity's sake the one dimensional case will be proven. For this proof let $f' = \frac{\partial f}{\partial x}$.

\begin{equation*}\begin{aligned}
\mathcal{L}e^{-\beta U}g &= \frac{1}{\beta}(e^{-\beta U}g)'' + \left(e^{-\beta U}g\,U' \right)'\\
&= e^{-\beta U}\left(g'U'+gU''-\beta gU'^2\frac{1}{\beta}g''-2g'U'+\beta gU'^2-gU'' \right)\\
&= e^{-\beta U}\left(\frac{1}{\beta}g'' - g'U'\right) = e^{-\beta U}\mathcal{L}^*g
\end{aligned}\end{equation*}
\end{proof}

Because of the linearity of the operators

\begin{equation*}
\varphi_n = \psi_n e^{-\beta U}
\end{equation*}

Remembering that $\varphi_0 = e^{-\beta U}$ up to a normalization constant, we get

\begin{equation}\label{eq:connectionBetweenEigenfunctions}
\psi_j = \frac{\varphi_j}{\varphi_0}.
\end{equation}

Similar to definition \ref{def:diffusionDist} we define the diffusion distance at time $t$ between any two points $x_0, x_1 \in \Omega$ as the distance between the corresponding probability densities at time $t$, initialized at $x_0$ and $x_1$. Letting $p_{x_i}(x,t)$ be the solution of \eqref{eq:fokkerplanck} with initial condition $p(x,0 | x_i, 0) = \delta(x,x_i)$ we set

\begin{definition}
\begin{equation*}
D_t^2(x_0,x_1) = ||p_{x_0}(\cdot, t) - p_{x_1}(\cdot, t) ||_{L^2(\Omega, w)}^2.
\end{equation*}
\end{definition}

\begin{lemma}\begin{equation*}
D_t^2(x_0,x_1) = \sum_{j\geq 1} e^{2\lambda_j t} (\psi_j(x_0)-\psi_j(x_1))^2.
\end{equation*}\end{lemma}

\begin{proof}
Using \eqref{eq:decompositionProbDistributionfFPO}, \eqref{eq:connectionBetweenEigenfunctions}, \eqref{eq:alternativeReprForCoefficients}, \eqref{eq:firstEigenfunctionConstant} and \eqref{eq:biorthonormality} we get

\begin{equation*}\begin{aligned}
||p_{x_0}(\cdot, t) - p_{x_1}(\cdot, t) ||_{L^2(\Omega, w)}^2 &=
\int_\Omega \left( \sum_{n\geq 0} e^{\lambda_n t}(\psi_n(x_0)-\psi_n(x_1)) \varphi_n(x)\right)^2\frac{1}{\varphi_0(x)}dx\\
&= \sum_{n\geq 1} \int_\Omega \frac{\varphi_n(x)^2}{\varphi_0(x)}dx \left(e^{\lambda_n t}(\psi_n(x_0)-\psi_n(x_1))\right)^2\\
&= \sum_{n\geq 1} \int_\Omega \varphi_n(x)\psi_n(x)dx \left(e^{\lambda_n t}(\psi_n(x_0)-\psi_n(x_1))\right)^2\\
&= \sum_{n\geq 1} e^{2 \lambda_n t}(\psi_n(x_0)-\psi_n(x_1))^2
\end{aligned}\end{equation*}
\end{proof}

Now, again analogously to \autoref{chap:diffusionMaps}, we define the $k$-dimensional diffusion map $\Psi_t(x)$ as the nonlinear mapping from the original space of configurations to the Euclidean space with coordinates defined by the values of the first $k$ eigenfunctions

\begin{definition}

\begin{equation*}
\Psi_t(x)=\begin{pmatrix}
  e^{\lambda_1 t}\psi_1(x) \\
  e^{\lambda_2 t}\psi_2(x) \\
  \vdots \\
  e^{\lambda_k t}\psi_k(x)
 \end{pmatrix}
\end{equation*}

\end{definition}











